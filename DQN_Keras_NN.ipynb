{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import gym\n",
    "from gym import wrappers\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork():\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Create NN\n",
    "        self.model = Sequential()  # Create the model, a *sequential* NN\n",
    "        self.model.add(Dense(hidden_size, activation='relu', name=\"hidden\")) # Create input layer, Dense indicating a fully connected layer\n",
    "        self.model.add(Dense(output_size , activation='relu', name=\"output\")) # Create output layer\n",
    "        self.model.compile(loss=\"mse\", optimizer=Adam())\n",
    "        self.model.build((1, input_size))\n",
    "        self.model.summary()\n",
    "\n",
    "        # Memory buffer\n",
    "        self.replay_buffer = deque(maxlen=1000)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.epsilon = 0.6\n",
    "        self.gamma = 0.8\n",
    "        self.decay = 0.95\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model.predict(input.reshape(1,4), verbose=0)\n",
    "\n",
    "    def ep_greedy(self, Q_values):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, 1)\n",
    "        else: \n",
    "            return np.argmax(Q_values)\n",
    "        \n",
    "        self.epsilon *= self.decay\n",
    "\n",
    "    def store_experience(self, state, action, reward, state_new, done):\n",
    "        experience = (state, action, reward, state_new, done)\n",
    "        self.replay_buffer.append(experience)\n",
    "    \n",
    "    def train(self, batch_size):\n",
    "        if len(self.replay_buffer) > batch_size:\n",
    "            experience_sample = random.sample(self.replay_buffer, batch_size)\n",
    "            x = np.array([e[0] for e in experience_sample])\n",
    "\n",
    "            # Construct target\n",
    "            y = self.model.predict(x,verbose=0)\n",
    "            x2 = np.array([e[3] for e in experience_sample])\n",
    "            Q2 = self.gamma * np.max(self.model.predict(x2,verbose=0), axis=1)\n",
    "            \n",
    "            for i,(s,a,r,s2,d) in enumerate(experience_sample):\n",
    "                y[i][a] = r\n",
    "                if not d:\n",
    "                    y[i][a] += Q2[i]\n",
    "\n",
    "            # Update\n",
    "            self.model.fit(x, y, batch_size=batch_size, epochs=1, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (1, 8)                    40        \n",
      "                                                                 \n",
      " output (Dense)              (1, 2)                    18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58\n",
      "Trainable params: 58\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:02<19:57,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/500 [00:20<22:52,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0, 9.0, 20.0, 13.0, 13.0, 14.0, 9.0, 15.0, 13.0, 12.0, 15.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 21/500 [00:58<29:06,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0, 9.0, 20.0, 13.0, 13.0, 14.0, 9.0, 15.0, 13.0, 12.0, 15.0, 9.0, 13.0, 17.0, 24.0, 20.0, 14.0, 17.0, 17.0, 12.0, 11.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 31/500 [01:40<31:22,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0, 9.0, 20.0, 13.0, 13.0, 14.0, 9.0, 15.0, 13.0, 12.0, 15.0, 9.0, 13.0, 17.0, 24.0, 20.0, 14.0, 17.0, 17.0, 12.0, 11.0, 18.0, 12.0, 12.0, 17.0, 17.0, 12.0, 8.0, 14.0, 11.0, 18.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 41/500 [02:16<29:58,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0, 9.0, 20.0, 13.0, 13.0, 14.0, 9.0, 15.0, 13.0, 12.0, 15.0, 9.0, 13.0, 17.0, 24.0, 20.0, 14.0, 17.0, 17.0, 12.0, 11.0, 18.0, 12.0, 12.0, 17.0, 17.0, 12.0, 8.0, 14.0, 11.0, 18.0, 10.0, 15.0, 8.0, 10.0, 19.0, 13.0, 11.0, 16.0, 13.0, 10.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 51/500 [03:18<43:04,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0, 9.0, 20.0, 13.0, 13.0, 14.0, 9.0, 15.0, 13.0, 12.0, 15.0, 9.0, 13.0, 17.0, 24.0, 20.0, 14.0, 17.0, 17.0, 12.0, 11.0, 18.0, 12.0, 12.0, 17.0, 17.0, 12.0, 8.0, 14.0, 11.0, 18.0, 10.0, 15.0, 8.0, 10.0, 19.0, 13.0, 11.0, 16.0, 13.0, 10.0, 11.0, 18.0, 35.0, 18.0, 16.0, 13.0, 18.0, 15.0, 16.0, 12.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 61/500 [04:12<37:28,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0, 9.0, 20.0, 13.0, 13.0, 14.0, 9.0, 15.0, 13.0, 12.0, 15.0, 9.0, 13.0, 17.0, 24.0, 20.0, 14.0, 17.0, 17.0, 12.0, 11.0, 18.0, 12.0, 12.0, 17.0, 17.0, 12.0, 8.0, 14.0, 11.0, 18.0, 10.0, 15.0, 8.0, 10.0, 19.0, 13.0, 11.0, 16.0, 13.0, 10.0, 11.0, 18.0, 35.0, 18.0, 16.0, 13.0, 18.0, 15.0, 16.0, 12.0, 12.0, 14.0, 19.0, 20.0, 18.0, 22.0, 15.0, 14.0, 11.0, 11.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 71/500 [05:32<1:24:52, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0, 9.0, 20.0, 13.0, 13.0, 14.0, 9.0, 15.0, 13.0, 12.0, 15.0, 9.0, 13.0, 17.0, 24.0, 20.0, 14.0, 17.0, 17.0, 12.0, 11.0, 18.0, 12.0, 12.0, 17.0, 17.0, 12.0, 8.0, 14.0, 11.0, 18.0, 10.0, 15.0, 8.0, 10.0, 19.0, 13.0, 11.0, 16.0, 13.0, 10.0, 11.0, 18.0, 35.0, 18.0, 16.0, 13.0, 18.0, 15.0, 16.0, 12.0, 12.0, 14.0, 19.0, 20.0, 18.0, 22.0, 15.0, 14.0, 11.0, 11.0, 22.0, 12.0, 12.0, 9.0, 14.0, 12.0, 13.0, 58.0, 39.0, 66.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 81/500 [06:45<51:00,  7.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.0, 9.0, 20.0, 13.0, 13.0, 14.0, 9.0, 15.0, 13.0, 12.0, 15.0, 9.0, 13.0, 17.0, 24.0, 20.0, 14.0, 17.0, 17.0, 12.0, 11.0, 18.0, 12.0, 12.0, 17.0, 17.0, 12.0, 8.0, 14.0, 11.0, 18.0, 10.0, 15.0, 8.0, 10.0, 19.0, 13.0, 11.0, 16.0, 13.0, 10.0, 11.0, 18.0, 35.0, 18.0, 16.0, 13.0, 18.0, 15.0, 16.0, 12.0, 12.0, 14.0, 19.0, 20.0, 18.0, 22.0, 15.0, 14.0, 11.0, 11.0, 22.0, 12.0, 12.0, 9.0, 14.0, 12.0, 13.0, 58.0, 39.0, 66.0, 32.0, 30.0, 13.0, 37.0, 25.0, 18.0, 14.0, 17.0, 50.0, 25.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 88/500 [07:33<37:09,  5.41s/it]  "
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1', render_mode=\"human\")\n",
    "\n",
    "s_size = env.observation_space.shape[0]\n",
    "a_size = env.action_space.n\n",
    "hidden_size = 8\n",
    "\n",
    "net = QNetwork(s_size, hidden_size, a_size)\n",
    "\n",
    "gamma = 0.85  \n",
    "\n",
    "rewards = []\n",
    "\n",
    "for g in tqdm(range(500)):\n",
    "    \n",
    "    game_reward = 0 \n",
    "    \n",
    "    done = False\n",
    "    state = env.reset()[0]\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        # Forward prop\n",
    "        Q_values = net.forward(state)\n",
    "        \n",
    "        # Policy Decision\n",
    "        Q_current = np.max(Q_values)\n",
    "        action = net.ep_greedy(Q_values)\n",
    "    \n",
    "        # Next step\n",
    "        state_next, reward, done, info, _ = env.step(action)\n",
    "        \n",
    "        net.store_experience(state, action, reward, state_next, done)\n",
    "\n",
    "        #Reward count\n",
    "        game_reward += reward\n",
    "\n",
    "        net.train(100)\n",
    "        \n",
    "        state = state_next\n",
    "\n",
    "    if done:\n",
    "        rewards.append(game_reward)\n",
    "        if g % 10 == 0:\n",
    "            print(rewards[:len(rewards) - 10])\n",
    "env.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
